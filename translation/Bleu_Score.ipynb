{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1AVMVNAm2QF",
        "outputId": "17f83daf-0775-4c25-edec-b8fb2930e21a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu"
      ],
      "metadata": {
        "id": "_A6kl0SinNpn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afcXXX4WnQvo",
        "outputId": "eec9cd2e-fc0f-4d53-ba63-66bf23558755"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Load the pretrained model and tokenizer\n",
        "model_name = \"/content/drive/MyDrive/model\"\n",
        "tokenizer_name = \"/content/drive/MyDrive/model\"\n",
        "\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "tokenizer = MarianTokenizer.from_pretrained(tokenizer_name)\n",
        "\n",
        "def translate(text, model, tokenizer):\n",
        "    '''\n",
        "    Function that translates a given text to Twi\n",
        "\n",
        "    Args:\n",
        "        text -> the text to be translated\n",
        "        trainer -> trainer instance that contains the model\n",
        "        tokenizer -> tokenizer instance to tokenize the text\n",
        "\n",
        "    Returns:\n",
        "        Transalted text\n",
        "    '''\n",
        "    input_encodings = tokenizer(text, return_tensors='pt', padding=True)\n",
        "\n",
        "    # Generate translation\n",
        "    translated_tokens = model.generate(**input_encodings)\n",
        "\n",
        "    # Decode the output\n",
        "    translated_text = [tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokens]\n",
        "\n",
        "    return translated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq3ZTZ8bnnqb",
        "outputId": "98683cae-f7e9-461f-ae86-9437d8324c67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:606: UserWarning: `num_beams` is set to None - defaulting to 1.\n",
            "  warnings.warn(\"`num_beams` is set to None - defaulting to 1.\", UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_bleu_score(references, hypotheses):\n",
        "    \"\"\"\n",
        "    Calculate BLEU score given reference translations and model predictions.\n",
        "\n",
        "    Args:\n",
        "    references: List of reference translations (list of lists of tokenized sentences)\n",
        "    hypotheses: List of model-generated translations (list of tokenized sentences)\n",
        "\n",
        "    Returns:\n",
        "    BLEU score for the predictions compared to the references.\n",
        "    \"\"\"\n",
        "    # Tokenize the reference and hypothesis translations\n",
        "    references = [[ref.split()] for ref in references]\n",
        "    hypotheses = [hyp.split() for hyp in hypotheses]\n",
        "\n",
        "    # Calculate the BLEU score\n",
        "    bleu_score = corpus_bleu(references, hypotheses)\n",
        "    return bleu_score"
      ],
      "metadata": {
        "id": "0ckCMk4HnUW6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = [\"I am very hungry\", \"She is sick and tired of painting\"]\n",
        "test_reference = [\"Ɔkɔm de me paa\", \"Ɔyare na wabrɛ wɔ mfoniniyɛ mu\"]\n",
        "translated_text = translate(test, model, tokenizer)\n",
        "\n",
        "# Generate model predictions\n",
        "predicted_twi_sentences = translate(test, model, tokenizer)\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = calculate_bleu_score(test_reference, predicted_twi_sentences)\n",
        "print(f\"BLEU Score on test set: {bleu_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g97-2pgUnj8K",
        "outputId": "2e29e362-e96d-4fe1-c9e2-ae874f6b78dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score on test set: 4.38832006142665e-78\n"
          ]
        }
      ]
    }
  ]
}